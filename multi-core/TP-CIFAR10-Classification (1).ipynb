{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP-CIFAR10-Classification","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6G7u6OSczxkj"},"source":["# TP Architecture des Systèmes Embarquées\n","\n","Dans ce TP nous allons créer et lancer l'apprentissage d'un modèle de classification d'images. Le modèle prendra une image en entrée et en sortie, prédit la classe de l'objet dans l'image. Ces taches sont très fréquents dans les systèmes autonomes comme les voitures afin de détecter les obstacles (piétons, autres voitures, paneaux de signalisations) et les drones de surveillance.\n","\n","Les algorithmes de machine learning domine le monde d'intélligence artificielle récemment. Pour cela, nous allons utiliser un modèle de classification basé sur le machine learning. Pour platforme logicielle, nous allons utiliser PyTorch.\n","\n","## Préparation de données\n","\n","La première étape de conception d'un modèle est l'apprentissage. Dans cette étape, nous allons fournir un ensemble d'images à l'algorithme. Ces images sont étiqueté par un humain. L'ordinateur essaira de trouver la relation entre l'image en entrée et la prédiction qu'il doit donner plus tard."]},{"cell_type":"markdown","metadata":{"id":"oeyb7iaw12lX"},"source":["1. Nous allons utiliser une base de données CIFAR10, disponible en ligne. Pour simplifier son importation, nous allons utiliser `torchvision`, une librairie de torch permettant de charger les données. D'abord, il faut importer ces librairie dans Jupyter."]},{"cell_type":"code","metadata":{"id":"YZmvtWUl6GPR"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VVQsZJX2Onv"},"source":["Ces prochaines lignes servent à importer la base de donnés et normaliser les images dedans. Cette étape est importante pour améliorer la qualité des résultats finaux."]},{"cell_type":"code","metadata":{"id":"BYJ1hk4VyQcW"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vhLNuRov2hHk"},"source":["**Dans la base de données, les classes sont codé par un entier de 0 à 9. Pourquoi cette codification?**\n","\n","Pour des raisons d'affichage, nous allons déclarer les 10 classes sous forme d'un tableau de chaine de caractères."]},{"cell_type":"code","metadata":{"id":"T60RPZ3h2hRD"},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qo1R2XejKKsi"},"source":["Nous allons afficher un extrait de cette base de donnés. Pour cela, nous utilisons `matplotlib`.\n","\n","La fonction `imshow` permet de restaurer l'image originale à partir d'une image normalisé et l'afficher dans le carnet."]},{"cell_type":"code","metadata":{"id":"6Afn_mOPyQ1A"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zvpSCAFcK_zE"},"source":["# Apprentissage\n","\n","L'étape suivante permet de définir le modèle de classification. Un modèle est une suite d'opérations organisé dans un pipeline. Un ensemble d'opération est appelé couche. Chaque couche prends la sortie de la précédente et fourni l'entré de la couche suivante. L'image est l'entrée de la première couche et la sortie de la dernière est la classe prédite pour l'objet."]},{"cell_type":"code","metadata":{"id":"8zjaB4C9yVlw"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = Net()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uqBJlYwLngq"},"source":["Un modèle a besoin d'un optimisateur qui vas essayer de minimiser son erreur. L'érreur est la différence entre ce qu'on veut avoir (le code de la classe entre 0 et 9) et ce que le modèle sort (un autres entier entre 0 et 9). Plus cette erreur est petite, mieux le réseaux reconnais les images."]},{"cell_type":"code","metadata":{"id":"A9Vnit26yYF4"},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0tO81cTME0x"},"source":["Une fois que tout est prêt, l'apprentissage commence. C'est une étape très gourmande en calcul. Nous allons passer les images au modèles en modifiant les parameters de celui ci après chaque passage. Sachant que la base de donnés contient 60000 images, toutes ces images doivent être passé au classifieur."]},{"cell_type":"code","metadata":{"id":"LC3sL9sXycAA"},"source":["for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n","PATH = './cifar_net.pth'\n","torch.save(net.state_dict(), PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vxt1IEpuG6CQ"},"source":["# Inférence\n","\n","La deuxième phase du Machine Learning est l'inférence. Une fois que le modèle est entrainé (phase apprentissage), il est prét pour générer des prédictions sur des nouveaux images.\n","Nous allons utiliser les images de la base de test. C'est une portion de la base de données qui n'est pas utilisé pour l'apprentissage.\n","D'abord, nous allons visualer une portion de ces images."]},{"cell_type":"code","metadata":{"id":"NV0G4MgDHTN6"},"source":["dataiter = iter(testloader)\n","images, labels = dataiter.next()\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wS2V0C2cDfY"},"source":["Nous allons charger le modèle que nous avons précédemment enregister après l'apprentissage."]},{"cell_type":"code","metadata":{"id":"s-7hiZ7_cN-v"},"source":["net = Net()\n","net.load_state_dict(torch.load(PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHgsnIX7cPnW"},"source":["Il ne reste qu'a lancer l'inférences sur les images que nous avons afficher précédemment."]},{"cell_type":"code","metadata":{"id":"e0iPcv7VcVY_"},"source":["outputs = net(images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xD971uGwcYLd"},"source":["On affiche les résultats pour comparer à la référence."]},{"cell_type":"code","metadata":{"id":"7pxqWGzmceMA"},"source":["_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3CMGra7IyjS"},"source":["Nous pouvons bien évidemment tester sur d'autres images. Pour cela, nous avons le dossier `test_data` dans lequel nous allons mettre ces images.\n","Télécharger une photo d'un objet de l'une des clases sur lesquels nous avons entrainé le modèle et mettez la dans le dossier `test_data`.\n","La taille des images doit être (32 * 32) avec 3 channels: R, G et B. Ce sont les paramètres que nous avons mis dans la première couche du réseaux en haut."]},{"cell_type":"code","metadata":{"id":"iglJ1aBKJ9Zf"},"source":["import os\n","from PIL import Image\n","\n","files = os.listdir('test_data')\n","for f in files:\n","  img = Image.open('test_data/'+f)\n","  resized = img.resize((32, 32))\n","  normalized = transform(np.array(resized))\n","  imshow(normalized)\n","  net_inp = normalized.reshape(1, 3, 32, 32)\n","  out = net(net_inp)\n","  _, predicted = torch.max(out, 1)\n","  print('GroundTruth: ', ' '.join('%5s' % classes[predicted[0]]))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BE4DfktRcvqy"},"source":["Pour calculer la précision du modèle nous allons le tester sur un grand nombre d'images dont on connais au paravent les classes. La précision est alors le nombre d'image correctement classifié sur le nombre total d'images."]},{"cell_type":"code","metadata":{"id":"8ZjmlJ-Wc7Co"},"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Précision du modèle sur 10000 images: %d %%' % (\n","    100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANXK-R3cdCMl"},"source":["# Sur GPU! Pourquoi et Comment ?\n","\n","Dans cette étape nous allons porter le modèle sur GPU. Avant de faire, nous allons calculer quelques temps d'exécution. On vous donne le code suivant qui permet de calculer le temps d'exécution d'une, ou plusieurs, instructions."]},{"cell_type":"code","metadata":{"id":"J8e_ZLSLdEVz"},"source":["import time\n","start = time.time()\n","# ATTENTION: Pour calculer le temps d'exécution, il faut pas laisser les affichages et les entrés sorties\n","# Lors du déploiement, un algorithme ne communiquer ces sortie que pour actionner des modules ou prendre des décision\n","a = 0\n","for i in range(10000000):\n","  a+=i\n","print(a)\n","end = time.time()\n","print(\"Temps d'exécution: {} secondes\".format(round(end-start, 4)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bor-YfKkdyBe"},"source":["**En utilisant cette technique, ecrivez deux fonctions `temps_cpu_app` et `temps_cpu_inf` pour estimer le temps d'exécuter de l'apprentissage et de l'inférence.**\n","\n","N'oubliez pas de commentez les lignes d'affichage. Pour l'inférence, il ne faut considérer que le temps que le modèle est en train de s'exécuter. Les temps de redimensionnement et de normalisation de l'image ne doivent pas être prises en compte.\n","\n","Attention: Le temps d'exécution pour les petites taches (comme l'inférence d'une image) peux varier. **Comment vérifier? Pourquoi cette variation? Que proposez vous pour avoir un temps plus précis?**\n","\n","## Porter le modèle sur GPU\n","\n","Toute algorithme s'exécute sur le CPU sauf si une autre plateforme est précisé. Si le temps d'exécution n'est pas satisfaisant pour les besoin de l'application, il faut porter le modèle sur des architecture plus puissants. Dans notre cas, Colab offre 2 types de platformes: les GPUs et les TPUs. Dans ce TP nous allons voir comment utiliser un GPU et quels sont les gains que l'on vas avoir.\n","\n","Pour lister les accélérateurs existants on utilise les instruction suivantes."]},{"cell_type":"code","metadata":{"id":"8_BN4VUdejsz"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62ueiUqQffmc"},"source":["Assurez vous d'avoir un résultat `cuda:0`. Si c'est pas le cas, changer le mode d'exécution dans \"Exécution ==> Mode d'exécution\" au GPU. Vous trouverez une liste déroulante contenant les options: None pour CPU, GPU et TPU. Réexécuter l'étape précédente jusqu'a ce que vous obtenez l'affiche demandé. En réalité, si un GPU est installé sur la machine, nous devons être capable de l'utiliser. Vu que Colab est une platforme virtuelle, le choix du matérielle est fait de cette façon.\n","\n","Jusqu'a maintenent, toute les opérations que nous avons fait ont été exécuté sur le CPU. Les paramètres du modèels sont stocké dans la mémoire centrale (RAM). Cette mémoire n'est physiquement connecté qu'au CPU. Le GPU, ayant une mémoire physique à lui, ne poura pas travailler sur ces valeurs. Il faut copier toute variable à la mémoire interne du GPU afin que l'on puisse l'utiliser. Pour cela, l'instruction suivante permet de copier le modèle au GPU."]},{"cell_type":"code","metadata":{"id":"zZye9FpNfxIk"},"source":["net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IJFyHbFwgt_B"},"source":["**Relancer les étapes précédentes, notamment inférence et apprentissage, en utilisant le GPU. Faites deux autres fonctions `temps_gpu_app` et `temps_gpu_inf` pour le temps d'exécution apprentissage et inférence sur GPU.**\n","\n","Attention! Les entrée doivent aussi être en GPU pour que l'exécution puisse se faire. Pour l'apprentissage par exemple, il faut remplacer la ligne `inputs, labels = data` par `inputs, labels = data[0].to(device), data[1].to(device)` pour que le GPU puissent lire les entrées.\n","\n","**Générez plusieurs modèles (10) en changent le nombre de couches, la taille de filtres dans chaque couche, la taille de l'image en entrés, etc. Pour chaque modèle calculer la précision de celui-ci, le temps d'exécution pour l'inférence et pour l'apprentissage.**\n","\n","**Tracer deux courbes à l'aide de `matplotlib` qui affichent la variation du temps d'exécution entre le CPU et le GPU pour chaque modèle.**"]},{"cell_type":"code","metadata":{"id":"dINr_CIwhYtl"},"source":["import random\n","def temps_cpu_app():\n","  return random.random()\n","def temps_cpu_inf():\n","  return random.random()\n","def temps_gpu_app():\n","  return random.random()\n","def temps_gpu_inf():\n","  return random.random()\n","\n","import matplotlib.pyplot as plt\n","\n","t_cpu_app = []\n","t_cpu_inf = []\n","t_gpu_app = []\n","t_gpu_inf = []\n","x = []\n","for i in range(10):\n","  t1 = temps_cpu_app()\n","  t2 = temps_cpu_inf()\n","  t3 = temps_gpu_app()\n","  t4 = temps_gpu_inf()\n","  t_cpu_app.append(t1)\n","  t_cpu_inf.append(t2)\n","  t_gpu_app.append(t3)\n","  t_gpu_inf.append(t4)\n","  x.append(i)\n","\n","plt.plot(x, t_cpu_app, label='CPU APP')\n","plt.plot(x, t_gpu_app, label='GPU APP')\n","plt.legend()\n","plt.show()\n","plt.plot(x, t_cpu_inf, label='CPU INF')\n","plt.plot(x, t_gpu_inf, label='GPU INF')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]}]}